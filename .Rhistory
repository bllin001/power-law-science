kable_classic_2(full_width = FALSE) %>%
row_spec(which(word_count$count == 0), bold = TRUE, color = "white", background = "red")
ggplot(word_count, aes(x = rank, y = count)) +
geom_point(aes(color = "observed")) +
geom_line(aes(color = "observed")) +
theme_bw() +
geom_point(aes(y = zipfs, color = "theoretical")) +
geom_line(aes(y = zipfs, color = "theoretical")) +
labs(x = "Rank", y = "Count", title = "Zipf's law visualization for Topic 0") +
scale_colour_manual(name = "Word count", values=c("theoretical" = "red", "observed" = "black")) +
theme(legend.position = "top")
Valores <- word_count$count
m_pl <- displ$new(Valores)
m_pl
est_pl <- estimate_xmin(m_pl)
est_pl
m_pl$setXmin(est_pl)
m_pl
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.4, 0), tck = -.01, cex.axis = 0.9, las = 1)
m_pl$setXmin(est_pl)
plot(m_pl, pch = 21, bg = 2, panel.first = grid(col = "grey80"),
xlab = "Number of occurrences ", ylab = "Acumulative probability")
lines(m_pl, col = 3, lwd = 3)
data.s <- unique(Valores)
d_est <- data.frame(X_min=sort(data.s)[1:(length(data.s)-2)], Alfa=rep(0,length(data.s)-2), D=rep(0,length(data.s)-2))
for (i in d_est$X_min){
d_est[which(d_est$X_min == i),2] <- estimate_xmin(m_pl, xmins = i)$pars
d_est[which(d_est$X_min == i),3] <- estimate_xmin(m_pl, xmins = i)$gof
}
d_est
X.min_D.min <- d_est[which.min(d_est$D), 1]
X.min_D.min
ggplot(data=d_est, aes(x=X_min, y=D)) +
geom_text(aes( x = X.min_D.min, y = d_est[which.min(D), 3], label=X.min_D.min ), vjust=3.5)+
geom_text(aes( x = X.min_D.min, y = d_est[which.min(D), 3], label="X.min" ), vjust=2)+
geom_text(aes( x = min(X_min), y = d_est[which.min(D), 3], label=round(d_est[which.min(D), 3],4) ), vjust=-0.5)+
geom_text(aes( x = min(X_min), y = d_est[which.min(D), 3], label="D.min"), vjust=-2)+
geom_line() +
theme_bw() +
#geom_vline(xintercept=X.min_D.min, colour="red") +
geom_segment(aes(x = X.min_D.min, xend = X.min_D.min, y = min(D)-0.02, yend = max(D)), linetype = "dashed", colour="red", size=0.7) +
geom_segment(aes(x = min(X_min), xend = X.min_D.min +1, y = min(D), yend = min(D)), linetype = "dashed", colour="red", size=0.7) +
labs(x = "Values of X_min", y = "Values of D", title = "X_min vs D")
#annotate("text", x=X.min_D.min, y=max(d_est$D)/3*2, label=X.min_D.min)
ggplot(data=d_est, aes(x=X_min, y=Alfa)) +
geom_text(aes( x = X.min_D.min, y = min(Alfa), label=X.min_D.min ), vjust=-0.5)+
geom_text(aes( x = X.min_D.min, y = min(Alfa), label="X.min" ), vjust=1)+
geom_text(aes( x = min(X_min), y = d_est[which.max(Alfa), 2], label=round(d_est[which.max(Alfa), 2],4) ), vjust=1.5)+
geom_text(aes( x = min(X_min), y = d_est[which.max(Alfa), 2], label="Alfa.max"), vjust=3)+
geom_line() +
theme_bw() +
#geom_vline(xintercept=X.min_D.min, colour="red") +
geom_segment(aes(x = X.min_D.min, xend = X.min_D.min, y = min(Alfa)-0.02, yend = max(Alfa)), linetype = "dashed", colour="red", size=0.7) +
geom_segment(aes(x = min(X_min), xend = X.min_D.min +1, y = d_est[which.max(Alfa), 2], yend = d_est[which.max(Alfa), 2]), linetype = "dashed", colour="red", size=0.7) +
labs(x = "Values of X_min", y = "Values of Alfa", title = "X_min vs Alfa")
#annotate("text", x=X.min_D.min, y=max(Alfa)/3*2, label=X.min_D.min)
m_pl$setXmin(est_pl)
Prob.emp <- plot(m_pl, draw = F)
Prob.emp
fit.data <- lines(m_pl, draw = F)
fit.data
ggplot(Prob.emp) + geom_point(aes(x=log(x), y=log(y))) + labs(x="log(k)", y="log(CDF)") + theme_bw() +
geom_line(data=fit.data, aes(x=log(x), y=log(y)), colour="red")
bootstrap_p(m_pl, seed = 123)
bs_pl <- bootstrap_p(m_pl, no_of_sims=1000, threads=8, seed = 123)
#threads=core number of processor that used by function
#parallel::detectCores() determines how many cores in your computer
bs_pl
mean(bs_pl$bootstraps[, 1]) # Media of gof (es el KS)
mean(bs_pl$bootstraps[, 2]) # Media of Xmin
mean(bs_pl$bootstraps[, 3]) # Media of pars (es el alfa, exponente)
mean(bs_pl$bootstraps[, 4]) # Media of ntail
sd(bs_pl$bootstraps[, 1]) # sd of gof (es el KS)
sd(bs_pl$bootstraps[, 2]) # sd of Xmin
sd(bs_pl$bootstraps[, 3]) # sd of pars (es el alfa, exponente)
sd(bs_pl$bootstraps[, 4]) # sd of ntail
Stat <- c("Measures", "gof (KS)", "xmin", "npars (alfa)", "ntail")
mean <- cbind("Mean", mean(bs_pl$bootstraps[, 1]), mean(bs_pl$bootstraps[, 2]), mean(bs_pl$bootstraps[, 3]), mean(bs_pl$bootstraps[, 4]))
SD <- cbind("SD", sd(bs_pl$bootstraps[, 1]), sd(bs_pl$bootstraps[, 2]), sd(bs_pl$bootstraps[, 3]), sd(bs_pl$bootstraps[, 4]))
Tabla <- data.frame(rbind(mean, SD))
names(Tabla) <- Stat
library(knitr) # para activar kable
library(kableExtra)
kable(Tabla, alig="ccccc", caption="Estimaciones de los parametros")  %>%
kable_styling() %>%                #library(kableExtra).... Solo para knit to html
kable_classic_2(full_width = F)   #library(kableExtra)....Solo para knit to html
bs_pl$p # P value
plot(bs_pl)
## trim=0.1 only displays the final 90% of iterations
plot(bs_pl, trim = 0.1)
hist(bs_pl$bootstraps[, 2]) # hist of Xmin
df_bs_pl <- bs_pl$bootstraps
ggplot(data=df_bs_pl, aes(xmin)) + geom_histogram() + labs(x="X_min", y="frequency") + theme_bw()
hist(bs_pl$bootstraps[, 3]) # hist of Ã­ndex s
df_bs_pl <- bs_pl$bootstraps
ggplot(data=df_bs_pl, aes(pars)) + geom_histogram() + labs(x="s", y="frequency") + theme_bw()
data.dist <- data.dist[data.dist$p_k>0,]
alfa_D.min <- d_est[which.min(d_est$D), 2] # Which Alfa corresponds to min of D
ggplot(data=df_bs_pl, aes(x=xmin, y=pars)) + labs(x="Values of X_min", y="Values of Alfa") + theme_bw() +
geom_point(shape=21, colour="black", fill="red", size=0.5, stroke=2,
position = position_jitter(), alpha=0.6) +
geom_vline(xintercept=X.min_D.min, colour="blue") +
geom_hline(yintercept=alfa_D.min, colour="blue") +
geom_text(aes( x = X.min_D.min-2, y = min(pars), label=X.min_D.min ), vjust=-0.5)+
geom_text(aes( x = X.min_D.min-2, y = min(pars), label="X.min" ), vjust=1)+
geom_text(aes( x = min(xmin)+5, y = alfa_D.min, label=round(alfa_D.min,4) ), vjust=-1.0)+
geom_text(aes( x = min(xmin)+5, y = alfa_D.min, label="Alfa.min"), vjust=-2.5)
setwd("/Users/brianllinas/Library/CloudStorage/OneDrive-OldDominionUniversity/VMASC/Projects/power-law-science")
#knitr::opts_chunk$\alphaet(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = "center") #solo para html
knitr::opts_chunk$set(fig.width = 8)
knitr::opts_chunk$set(dpi = 1200)
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(sads)
library(latexpdf)
library(igraph)
library(poweRlaw)
install.packages("ggplot2")
install.packages("dplyr")
install.packages("tidyr")
install.packages("kableExtra")
install.packages("sads")
install.packages("latexpdf")
install.packages("igraph")
install.packages("poweRlaw")
install.packages("ggplot2")
install.packages("dplyr")
install.packages("tidyr")
install.packages("kableExtra")
install.packages("sads")
install.packages("latexpdf")
install.packages(c("ggplot2", "dplyr", "tidyr", "kableExtra", "sads", "latexpdf", "igraph", "poweRlaw"))
install.packages(c("ggplot2", "dplyr", "tidyr", "kableExtra", "sads", "latexpdf", "igraph", "poweRlaw"))
install.packages("ggplot2")
install.packages("dplyr")
install.packages("tidyr")
install.packages("kableExtra")
install.packages("sads")
install.packages("latexpdf")
install.packages("igraph")
install.packages("poweRlaw")
install.packages("kableExtra")
install.packages("kableExtra")
install.packages("poweRlaw")
#knitr::opts_chunk$\alphaet(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = "center") #solo para html
knitr::opts_chunk$set(fig.width = 8)
knitr::opts_chunk$set(dpi = 1200)
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(sads)
library(latexpdf)
library(igraph)
library(poweRlaw)
# Data Lecture
data <- read.csv("../data/power_law.csv")
data
# data[c(1:5,(NROW(data)-5):NROW(data)),] %>%
#   kable(align = "lcc")  %>% #solo para html
#   kable_styling() %>%
#   kable_classic_2(full_width = F)
# Data clean
data_clean <- data %>%
filter(topic == 0,
Cited.by > 0) %>%
select(Title, Cited.by)
data_clean
# Zip Analysis
# Set alpha value
alpha <- 1
# Perform the Zipf analysis
word_count <- data_clean %>%
arrange(desc(Cited.by)) %>%
mutate(factor = Title,
count = Cited.by,
prop = round(count / sum(count), 2),
relation = round(first(count) / count, 2),
rank = row_number(),
zipfs = ifelse(rank == 1, count,
round(first(count) / rank^alpha, 2)),
error = round(abs(zipfs - count) / zipfs, 2)
) %>%
relocate(rank, .before = factor)
# Display the results in a table
word_count %>%
kable(align = "lcc") %>%
kable_styling(latex_options = "HOLD_position") %>%
kable_classic_2(full_width = FALSE) %>%
row_spec(which(word_count$count == 0), bold = TRUE, color = "white", background = "red")
ggplot(word_count, aes(x = rank, y = count)) +
geom_point(aes(color = "observed")) +
geom_line(aes(color = "observed")) +
theme_bw() +
geom_point(aes(y = zipfs, color = "theoretical")) +
geom_line(aes(y = zipfs, color = "theoretical")) +
labs(x = "Rank", y = "Count", title = "Zipf's law visualization for Topic 0") +
scale_colour_manual(name = "Word count", values=c("theoretical" = "red", "observed" = "black")) +
theme(legend.position = "top")
Valores <- word_count$count
m_pl <- displ$new(Valores)
m_pl
est_pl <- estimate_xmin(m_pl)
est_pl
m_pl$setXmin(est_pl)
m_pl
par(mar = c(3, 3, 2, 1), mgp = c(2, 0.4, 0), tck = -.01, cex.axis = 0.9, las = 1)
m_pl$setXmin(est_pl)
plot(m_pl, pch = 21, bg = 2, panel.first = grid(col = "grey80"),
xlab = "Number of occurrences ", ylab = "Acumulative probability")
lines(m_pl, col = 3, lwd = 3)
data.s <- unique(Valores)
d_est <- data.frame(X_min=sort(data.s)[1:(length(data.s)-2)], Alfa=rep(0,length(data.s)-2), D=rep(0,length(data.s)-2))
for (i in d_est$X_min){
d_est[which(d_est$X_min == i),2] <- estimate_xmin(m_pl, xmins = i)$pars
d_est[which(d_est$X_min == i),3] <- estimate_xmin(m_pl, xmins = i)$gof
}
d_est
X.min_D.min <- d_est[which.min(d_est$D), 1]
X.min_D.min
ggplot(data=d_est, aes(x=X_min, y=D)) +
geom_text(aes( x = X.min_D.min, y = d_est[which.min(D), 3], label=X.min_D.min ), vjust=3.5)+
geom_text(aes( x = X.min_D.min, y = d_est[which.min(D), 3], label="X.min" ), vjust=2)+
geom_text(aes( x = min(X_min), y = d_est[which.min(D), 3], label=round(d_est[which.min(D), 3],4) ), vjust=-0.5)+
geom_text(aes( x = min(X_min), y = d_est[which.min(D), 3], label="D.min"), vjust=-2)+
geom_line() +
theme_bw() +
#geom_vline(xintercept=X.min_D.min, colour="red") +
geom_segment(aes(x = X.min_D.min, xend = X.min_D.min, y = min(D)-0.02, yend = max(D)), linetype = "dashed", colour="red", size=0.7) +
geom_segment(aes(x = min(X_min), xend = X.min_D.min +1, y = min(D), yend = min(D)), linetype = "dashed", colour="red", size=0.7) +
labs(x = "Values of X_min", y = "Values of D", title = "X_min vs D")
#annotate("text", x=X.min_D.min, y=max(d_est$D)/3*2, label=X.min_D.min)
ggplot(data=d_est, aes(x=X_min, y=Alfa)) +
geom_text(aes( x = X.min_D.min, y = min(Alfa), label=X.min_D.min ), vjust=-0.5)+
geom_text(aes( x = X.min_D.min, y = min(Alfa), label="X.min" ), vjust=1)+
geom_text(aes( x = min(X_min), y = d_est[which.max(Alfa), 2], label=round(d_est[which.max(Alfa), 2],4) ), vjust=1.5)+
geom_text(aes( x = min(X_min), y = d_est[which.max(Alfa), 2], label="Alfa.max"), vjust=3)+
geom_line() +
theme_bw() +
#geom_vline(xintercept=X.min_D.min, colour="red") +
geom_segment(aes(x = X.min_D.min, xend = X.min_D.min, y = min(Alfa)-0.02, yend = max(Alfa)), linetype = "dashed", colour="red", size=0.7) +
geom_segment(aes(x = min(X_min), xend = X.min_D.min +1, y = d_est[which.max(Alfa), 2], yend = d_est[which.max(Alfa), 2]), linetype = "dashed", colour="red", size=0.7) +
labs(x = "Values of X_min", y = "Values of Alfa", title = "X_min vs Alfa")
#annotate("text", x=X.min_D.min, y=max(Alfa)/3*2, label=X.min_D.min)
m_pl$setXmin(est_pl)
Prob.emp <- plot(m_pl, draw = F)
Prob.emp
fit.data <- lines(m_pl, draw = F)
fit.data
ggplot(Prob.emp) + geom_point(aes(x=log(x), y=log(y))) + labs(x="log(k)", y="log(CDF)") + theme_bw() +
geom_line(data=fit.data, aes(x=log(x), y=log(y)), colour="red")
bootstrap_p(m_pl, seed = 123)
bs_pl <- bootstrap_p(m_pl, no_of_sims=1000, threads=8, seed = 123)
#threads=core number of processor that used by function
#parallel::detectCores() determines how many cores in your computer
bs_pl
mean(bs_pl$bootstraps[, 1]) # Media of gof (es el KS)
mean(bs_pl$bootstraps[, 2]) # Media of Xmin
mean(bs_pl$bootstraps[, 3]) # Media of pars (es el alfa, exponente)
mean(bs_pl$bootstraps[, 4]) # Media of ntail
sd(bs_pl$bootstraps[, 1]) # sd of gof (es el KS)
sd(bs_pl$bootstraps[, 2]) # sd of Xmin
sd(bs_pl$bootstraps[, 3]) # sd of pars (es el alfa, exponente)
sd(bs_pl$bootstraps[, 4]) # sd of ntail
Stat <- c("Measures", "gof (KS)", "xmin", "npars (alfa)", "ntail")
mean <- cbind("Mean", mean(bs_pl$bootstraps[, 1]), mean(bs_pl$bootstraps[, 2]), mean(bs_pl$bootstraps[, 3]), mean(bs_pl$bootstraps[, 4]))
SD <- cbind("SD", sd(bs_pl$bootstraps[, 1]), sd(bs_pl$bootstraps[, 2]), sd(bs_pl$bootstraps[, 3]), sd(bs_pl$bootstraps[, 4]))
Tabla <- data.frame(rbind(mean, SD))
names(Tabla) <- Stat
library(knitr) # para activar kable
library(kableExtra)
kable(Tabla, alig="ccccc", caption="Estimaciones de los parametros")  %>%
kable_styling() %>%                #library(kableExtra).... Solo para knit to html
kable_classic_2(full_width = F)   #library(kableExtra)....Solo para knit to html
bs_pl$p # P value
bs_pl$p # P value
plot(bs_pl)
## trim=0.1 only displays the final 90% of iterations
plot(bs_pl, trim = 0.1)
hist(bs_pl$bootstraps[, 2]) # hist of Xmin
df_bs_pl <- bs_pl$bootstraps
ggplot(data=df_bs_pl, aes(xmin)) + geom_histogram() + labs(x="X_min", y="frequency") + theme_bw()
hist(bs_pl$bootstraps[, 3]) # hist of Ã­ndex s
df_bs_pl <- bs_pl$bootstraps
ggplot(data=df_bs_pl, aes(pars)) + geom_histogram() + labs(x="s", y="frequency") + theme_bw()
data.dist <- data.dist[data.dist$p_k>0,]
alfa_D.min <- d_est[which.min(d_est$D), 2] # Which Alfa corresponds to min of D
ggplot(data=df_bs_pl, aes(x=xmin, y=pars)) + labs(x="Values of X_min", y="Values of Alfa") + theme_bw() +
geom_point(shape=21, colour="black", fill="red", size=0.5, stroke=2,
position = position_jitter(), alpha=0.6) +
geom_vline(xintercept=X.min_D.min, colour="blue") +
geom_hline(yintercept=alfa_D.min, colour="blue") +
geom_text(aes( x = X.min_D.min-2, y = min(pars), label=X.min_D.min ), vjust=-0.5)+
geom_text(aes( x = X.min_D.min-2, y = min(pars), label="X.min" ), vjust=1)+
geom_text(aes( x = min(xmin)+5, y = alfa_D.min, label=round(alfa_D.min,4) ), vjust=-1.0)+
geom_text(aes( x = min(xmin)+5, y = alfa_D.min, label="Alfa.min"), vjust=-2.5)
D.min <- d_est[which.min(d_est$D), 3] # Which D corresponds to min of Alfa
ggplot(data=df_bs_pl, aes(gof)) + geom_histogram() + labs(x="Values of D", y="Frequency") + geom_vline(xintercept=D.min, colour="red") + theme_bw()
#generate Xmin & kmax pairs
pairs <- as.data.frame(t(combn(sort(data.s), 2)))
pairs$D <- rep(0, length(pairs$V1))
pairs$gamma <- rep(0, length(pairs$V1))
pairs
#scan D for all Xmin-kmax pairs
for (i in 1:length(pairs$D)){
m_pl$setXmin(pairs[i,1])
pairs[i,3]<- estimate_xmin(m_pl, xmin = pairs[i,1], xmax = pairs[i,2], distance = "ks")$gof
pairs[i,4]<- estimate_xmin(m_pl, xmin = pairs[i,1], xmax = pairs[i,2], distance = "ks")$pars
}
head(pairs)
bs_pl_sat_cut <- bootstrap_p(m_pl, xmins = pairs[which.min(pairs$D), 1], xmax = pairs[which.min(pairs$D), 2], no_of_sims = 1000, threads = 8)
#knitr::opts_chunk$\alphaet(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig.align = "center") #solo para html
knitr::opts_chunk$set(fig.width = 8)
knitr::opts_chunk$set(dpi = 1200)
library(ggplot2)
library(dplyr)
library(tidyr)
library(kableExtra)
library(sads)
library(latexpdf)
library(igraph)
library(poweRlaw)
library(readr)
# Data Lecture
# library(readr)
data <- read.csv("/data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("./data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("../data/all_keywords_frequency.csv")
setwd("/Users/user/Library/CloudStorage/OneDrive-OldDominionUniversity/VMASC/Projects/power-law-science")
# Data Lecture
# library(readr)
data <- read.csv("../data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("./data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("/data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("../data/all_keywords_frequency.csv")
# Data Lecture
# library(readr)
data <- read.csv("../data/all_keyword_frequency.csv")
head(data)
# data[c(1:5,(NROW(data)-5):NROW(data)),] %>%
#   kable(align = "lcc")  %>% #solo para html
#   kable_styling() %>%
#   kable_classic_2(full_width = F)
# Zip Analysis
# Set alpha value
alpha <- 1
# Perform the Zipf analysis
word_count <- data %>%
arrange(desc(Total)) %>%
mutate(factor = Concepts,
count = Total,
prop = round(count / sum(count), 2),
relation = round(first(count) / count, 2),
rank = row_number(),
zipfs = ifelse(rank == 1, count,
round(first(count) / rank^alpha, 2)),
error = round(abs(zipfs - count) / zipfs, 2)
) %>%
relocate(rank, .before = factor)
df.word_count <- word_count
head(df.word_count)
dim(df.word_count)
# Display the results in a table
word_count %>%
kable(align = "lcc") %>%
kable_styling(latex_options = "HOLD_position") %>%
kable_classic_2(full_width = FALSE) %>%
row_spec(which(word_count$count == 0), bold = TRUE,
color = "white", background = "red")
library(openxlsx)
write.xlsx(df.word_count, "all_keywords_word_count.xls",
sheetName = "hoja_de_trabajo", rowNames = FALSE)
write.csv(df.word_count,file="all_keywords_word_count.csv")
ggplot(word_count, aes(x = rank, y = count)) +
geom_point(aes(color = "observed")) +
geom_line(aes(color = "observed")) +
theme_bw() +
geom_point(aes(y = zipfs, color = "theoretical")) +
geom_line(aes(y = zipfs, color = "theoretical")) +
labs(x = "Rank", y = "Count", title = "Zipf's law visualization for Topic 0") +
scale_colour_manual(name = "Word count", values=c("theoretical" = "red", "observed" = "black")) +
theme(legend.position = "top")
Valores <- word_count$count
m_pl <- displ$new(Valores)
#m_pl
est_pl <- estimate_xmin(m_pl)
est_pl
est_pl <- estimate_xmin(m_pl)
est_pl
MyLabel <- c("Method", "alfa", "sd_alfa", "Xmin", "sd_xmin", "ntail", "sd_ntail", "Stat", "sd_stat", "P_value")
alfa <-round(est_pl$pars, 3)
sd_alfa<-"NA"
xmin <-round(est_pl$xmin, 3)
sd_xmin <-"NA"
ntail <-round(est_pl$ntail, 3)
sd_ntail <-"NA"
stat <- round(est_pl$gof, 3)
sd_stat <-"NA"
P_value <- "NA"
KS_result <- c("MLE-KS",  alfa , sd_alfa, xmin, sd_xmin, ntail, sd_ntail, stat, sd_stat, P_value)
KS_df <- data.frame(rbind(KS_result))
names(KS_df) <- MyLabel
KS_df
m_pl$setXmin(est_pl)
#m_pl
bs_pl <- bootstrap_p(m_pl, no_of_sims=1000, threads=8, seed = 123)
#threads=core number of processor that used by function
#parallel::detectCores() determines how many cores in your computer
bs_pl
MyLabel <- c("Method", "alfa", "sd_alfa", "Xmin", "sd_xmin", "ntail", "sd_ntail", "Stat", "sd_stat", "P_value")
alfa <- round(mean(bs_pl$bootstraps[, 3]),3) # Media of pars (es el alfa, exponente)
sd_alfa<-round(sd(bs_pl$bootstraps[, 3]),3) # sd of pars (es el alfa, exponente)
xmin <-round(mean(bs_pl$bootstraps[, 2]),3) # Media of Xmin
sd_xmin <-round(sd(bs_pl$bootstraps[, 2]),3) # sd of Xmin
ntail <-round(mean(bs_pl$bootstraps[, 4]),3) # Media of ntail
sd_ntail <- round(sd(bs_pl$bootstraps[, 4]),3) # sd of ntail
stat <- round(mean(bs_pl$bootstraps[, 1]),3) # Media of gof (es el KS)
sd_stat <- round(sd(bs_pl$bootstraps[, 1]),3) # sd of gof (es el KS)
P_value <- round(bs_pl$p,3)
boot_result <- c("Bootstrapping", alfa , sd_alfa, xmin, sd_xmin, ntail, sd_ntail, stat, sd_stat, P_value)
boot_df <- data.frame(rbind(boot_result))
names(boot_df) <- MyLabel
boot_df
Estimation <- data.frame(rbind(KS_df, boot_df))
library(openxlsx)
write.xlsx(Estimation, "all_keywords_Estimation.xls",
sheetName = "hoja_de_trabajo", rowNames = FALSE)
write.csv(Estimation,file="all_keywords_Estimation.csv")
word_count <- data %>%
arrange(desc(Total)) %>%
mutate(count = Total,
proportion = round(count / sum(count), 2),
relation = round(first(count) / count, 2),
rank = row_number(),
) %>%
relocate(rank, .before = Concepts)
df.word_count <- word_count %>%
select(rank, Concepts, count, proportion, relation)
# Display the results in a table
word_count %>%
kable(align = "lcc") %>%
kable_styling(latex_options = "HOLD_position") %>%
kable_classic_2(full_width = FALSE) %>%
row_spec(which(word_count$count == 0), bold = TRUE,
color = "white", background = "red")
word_count <- data %>%
arrange(desc(Total)) %>%
mutate(count = Total,
proportion = round(count / sum(count), 2),
relation = round(first(count) / count, 2),
rank = row_number(),
) %>%
relocate(rank, .before = Concepts)
df.word_count <- word_count %>%
select(rank, Concepts, Total, proportion, relation)
# Display the results in a table
df.word_count %>%
kable(align = "lcc") %>%
kable_styling(latex_options = "HOLD_position") %>%
kable_classic_2(full_width = FALSE) %>%
word_count <- data %>%
arrange(desc(Total)) %>%
mutate(count = Total,
proportion = round(count / sum(count), 2),
relation = round(first(count) / count, 2),
rank = row_number(),
) %>%
relocate(rank, .before = Concepts)
df.word_count <- word_count %>%
select(rank, Concepts, Total, proportion, relation)
# Display the results in a table
df.word_count %>%
kable(align = "lcc") %>%
kable_styling(latex_options = "HOLD_position") %>%
kable_classic_2(full_width = FALSE)
library(openxlsx)
write.xlsx(df.word_count, "all_keywords_word_count.xls",
sheetName = "analysis", rowNames = FALSE)
write.csv(df.word_count,file="all_keywords_word_count.csv")
ggplot(df.word_count, aes(x = rank, y = Total)) +
geom_point(color = "blue") +
theme_bw() +
labs(x = "Rank", y = "Count", title = "Zipf's law visualization for Topic 0") +
theme(legend.position = "top")
ggplot(df.word_count, aes(x = rank, y = Total)) +
geom_point(color = "blue") +
theme_bw() +
labs(x = "Rank", y = "Count", title = "Ranking Distribution") +
theme(legend.position = "top")
ggplot(df.word_count, aes(x = rank, y = Total)) +
geom_point(color = "blue") +
theme_bw() +
labs(x = "Rank", y = "Count", title = "Ranking Distribution for all keywords") +
theme(legend.position = "top")
